{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f54d9e59-2493-4d49-9f4a-83d3ce4efdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67907df4-c65e-4faf-a06c-acb451d8e1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conn = sqlite3.connect(\"onet_data.db\")\n",
    "\n",
    "\n",
    "def load_csv_to_sqlite(file_path, table_name, chunk_size=50000):\n",
    "    for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n",
    "        chunk.to_sql(table_name, conn, if_exists=\"append\", index=False)\n",
    "\n",
    "\n",
    "load_csv_to_sqlite(r\"C:\\Users\\Skmal\\OneDrive\\Desktop\\datasets\\Occupation Data.csv\", \"occupation_data\")\n",
    "load_csv_to_sqlite(r\"C:\\Users\\Skmal\\OneDrive\\Desktop\\datasets\\Skills.csv\", \"skills_data\")\n",
    "load_csv_to_sqlite(r\"C:\\Users\\Skmal\\OneDrive\\Desktop\\datasets\\Task Statements.csv\", \"task_statements\")\n",
    "load_csv_to_sqlite(r\"C:\\Users\\Skmal\\OneDrive\\Desktop\\datasets\\Work Activities.csv\", \"work_activities\")\n",
    "load_csv_to_sqlite(r\"C:\\Users\\Skmal\\OneDrive\\Desktop\\datasets\\Technology Skills.csv\", \"technology_skills\")\n",
    "load_csv_to_sqlite(r\"C:\\Users\\Skmal\\OneDrive\\Desktop\\datasets\\Knowledge.csv\", \"knowledge_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb2721b0-8816-42c8-b39f-ec8b6f12fff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query = \"\"\"\n",
    "SELECT o.Title, o.Description, \n",
    "       s.\"Element Name\" AS Skills, \n",
    "       t.Task, \n",
    "       w.\"Element Name\" AS Activities, \n",
    "       ts.Example AS TechnologySkills, \n",
    "       k.\"Element Name\" AS Knowledge\n",
    "FROM occupation_data o\n",
    "LEFT JOIN skills_data s ON o.\"O*NET-SOC Code\" = s.\"O*NET-SOC Code\"\n",
    "LEFT JOIN task_statements t ON o.\"O*NET-SOC Code\" = t.\"O*NET-SOC Code\"\n",
    "LEFT JOIN work_activities w ON o.\"O*NET-SOC Code\" = w.\"O*NET-SOC Code\"\n",
    "LEFT JOIN technology_skills ts ON o.\"O*NET-SOC Code\" = ts.\"O*NET-SOC Code\"\n",
    "LEFT JOIN knowledge_data k ON o.\"O*NET-SOC Code\" = k.\"O*NET-SOC Code\"\n",
    "LIMIT 50000\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "job_profiles = pd.read_sql_query(query, conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c08ce51b-c6d6-4bb8-b191-e63c9b217ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50000 job profiles to job_profiles.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "job_profiles[\"Job Profile\"] = (\n",
    "    job_profiles[\"Title\"] + \" \" +\n",
    "    job_profiles[\"Description\"].fillna(\"\") + \" \" +\n",
    "    job_profiles[\"Skills\"].fillna(\"\") + \" \" +\n",
    "    job_profiles[\"Task\"].fillna(\"\") + \" \" +\n",
    "    job_profiles[\"Activities\"].fillna(\"\") + \" \" +\n",
    "    job_profiles[\"TechnologySkills\"].fillna(\"\") + \" \" +\n",
    "    job_profiles[\"Knowledge\"].fillna(\"\")\n",
    ")\n",
    "\n",
    "\n",
    "job_profiles.to_csv(\"job_profiles.csv\", index=False)\n",
    "print(f\"Saved {len(job_profiles)} job profiles to job_profiles.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87c149f1-f87e-4d72-89c6-78abc20a409c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Skmal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import InputExample\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "job_profiles = pd.read_csv(\"job_profiles.csv\")\n",
    "\n",
    "\n",
    "training_examples = []\n",
    "for _, row in job_profiles.iterrows():\n",
    "    training_examples.append(InputExample(\n",
    "        texts=[row[\"Title\"], row[\"Job Profile\"]],\n",
    "        label=1.0  \n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c159f5a8-7dfe-4e49-afb3-0620c8695b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, losses\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(training_examples, shuffle=True, batch_size=16)\n",
    "\n",
    "\n",
    "train_loss = losses.CosineSimilarityLoss(model)\n",
    "\n",
    "\n",
    "def train_with_checkpointing(model, train_dataloader, train_loss, epochs=3, output_path=\"job_title_model\"):\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        model.fit(\n",
    "            train_objectives=[(train_dataloader, train_loss)],\n",
    "            epochs=1,  \n",
    "            warmup_steps=100,\n",
    "            output_path=f\"{output_path}_epoch_{epoch + 1}\"  \n",
    "        )\n",
    "        print(f\"Checkpoint saved for epoch {epoch + 1} at {output_path}_epoch_{epoch + 1}\")\n",
    "\n",
    "\n",
    "train_with_checkpointing(model, train_dataloader, train_loss, epochs=3, output_path=\"job_title_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a4c6108-e874-4c35-8b0c-c6b9fe7fd9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "model.save(\"job_title_model_final\")\n",
    "print(\"Model saved\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
